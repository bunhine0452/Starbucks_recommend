{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkonlpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mecab\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfont_manager\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfm\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 한글 폰트 설정\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# MeCab 사전 경로 설정\n",
    "mecab = Mecab(dicpath='/opt/homebrew/lib/mecab/dic/mecab-ko-dic')\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('./data/스타벅스블로그본문.csv')\n",
    "df = df.head(1)\n",
    "# 불용어 리스트\n",
    "stopwords = ['스타벅스', '스타', '벅스', '스벅', '매장', '카페']\n",
    "\n",
    "# 불용어 제거 함수\n",
    "def remove_stopwords(text, stopwords):\n",
    "    for word in stopwords:\n",
    "        text = text.replace(word, '')\n",
    "    return text\n",
    "\n",
    "# 본문에서 불용어 제거\n",
    "df['Content'] = df['Content'].apply(lambda x: remove_stopwords(x, stopwords))\n",
    "\n",
    "# 명사 추출 함수\n",
    "def extract_nouns(text):\n",
    "    nouns = mecab.nouns(text)\n",
    "    return nouns\n",
    "\n",
    "# 전체 본문에서 명사 추출\n",
    "df['nouns'] = df['Content'].apply(extract_nouns)\n",
    "\n",
    "# 명사 빈도수 계산\n",
    "all_nouns = sum(df['nouns'].tolist(), [])\n",
    "noun_counts = Counter(all_nouns)\n",
    "\n",
    "# 1번씩만 나오는 키워드 및 글자 개수가 1개인 단어 제거\n",
    "filtered_noun_counts = {noun: count for noun, count in noun_counts.items() if count > 1 and len(noun) > 1}\n",
    "\n",
    "# 상위 1000개 명사 출력\n",
    "top_10_nouns = Counter(filtered_noun_counts).most_common(1000)\n",
    "print(top_10_nouns)\n",
    "\n",
    "# 데이터 준비\n",
    "nouns, counts = zip(*top_10_nouns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Store_Name                                              nouns  \\\n",
      "0   스타벅스 을지로4가역점  [커피, 디저트, 여행, 을지로4가역, 을지로4가역, 점, 내, 돈, 내산, 후기,...   \n",
      "1  스타벅스 을지로경기빌딩점  [냠냠, 지로, 대형, 지로, 경기, 빌딩, 점, 녜, 다, 이용, 저, 지로, 밥...   \n",
      "2  스타벅스 을지로국제빌딩점  [서울, 서울, 중구, 다동, 에코, 지로, 국제, 빌딩, 점, 이용한, 리유, 블...   \n",
      "3  스타벅스 을지로삼화타워점  [을지로입구역, 을지로입구역, 리유, 블, 컵, 코, 지로, 삼화, 타워, 점, 주...   \n",
      "4  스타벅스 을지로한국빌딩점  [리뷰, 로그, 내, 돈, 내산, 을지로, 한국, 빌딩, 점, 라떼, 후기, 구구,...   \n",
      "\n",
      "                                           frequency  \n",
      "0  {'커피': 7, '디저트': 8, '여행': 5, '을지로4가역': 52, '내산...  \n",
      "1  {'지로': 45, '경기': 49, '빌딩': 53, '이용': 8, '블로그':...  \n",
      "2  {'서울': 16, '중구': 15, '에코': 17, '지로': 60, '국제':...  \n",
      "3  {'을지로입구역': 20, '리유': 19, '지로': 22, '삼화': 55, '...  \n",
      "4  {'리뷰': 5, '내산': 4, '을지로': 30, '한국': 16, '빌딩': ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "from collections import Counter\n",
    "\n",
    "# MeCab 사전 경로 설정\n",
    "mecab = Mecab(dicpath='/opt/homebrew/lib/mecab/dic/mecab-ko-dic')\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('./data/스타벅스블로그본문.csv')\n",
    "\n",
    "# 불용어 리스트\n",
    "stopwords = ['스타벅스', '스타', '벅스', '스벅', '매장', '카페']\n",
    "\n",
    "# 불용어 제거 함수\n",
    "def remove_stopwords(text, stopwords):\n",
    "    if not isinstance(text, str):  # NaN 값 처리\n",
    "        return ''\n",
    "    for word in stopwords:\n",
    "        text = text.replace(word, '')\n",
    "    return text\n",
    "\n",
    "# 명사 추출 함수\n",
    "def extract_nouns(text):\n",
    "    nouns = mecab.nouns(text)\n",
    "    return nouns\n",
    "\n",
    "# 본문에서 불용어 제거 및 명사 추출\n",
    "df['Content'] = df['Content'].apply(lambda x: remove_stopwords(x, stopwords))\n",
    "df['nouns'] = df['Content'].apply(extract_nouns)\n",
    "\n",
    "# 각 매장별 명사 빈도수 계산 및 저장\n",
    "def calculate_frequencies(nouns):\n",
    "    noun_counts = Counter(nouns)\n",
    "    filtered_noun_counts = {noun: count for noun, count in noun_counts.items() if count > 1 and len(noun) > 1}\n",
    "    return filtered_noun_counts\n",
    "\n",
    "df['frequency'] = df['nouns'].apply(calculate_frequencies)\n",
    "\n",
    "# Content 칼럼 삭제\n",
    "df = df.drop(columns=['Content'])\n",
    "\n",
    "# 결과 저장\n",
    "df.to_csv('./data/스타벅스매장별키워드빈도.csv', index=False)\n",
    "\n",
    "# 결과 출력\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.read_csv('./data/필터링된스타벅스키워드빈도.csv')\n",
    "freq = freq.drop(columns='nouns')\n",
    "freq.to_csv('./data/스타벅스키워드빈도.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
